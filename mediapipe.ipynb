{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "pose = mp_pose.Pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def calculate_angles(firstPoint, midPoint, lastPoint):\n",
    "  # Same formula from the Android App for consistency\n",
    "  result = math.degrees(math.atan2(lastPoint.y  - midPoint.y, lastPoint.x - midPoint.x) - math.atan2(firstPoint.y - midPoint.y, firstPoint.x - midPoint.x))\n",
    "  result = abs(result) # Angle should never be negative\n",
    "  # \n",
    "  if result > 180:\n",
    "      result = 360.0 - result # Always get the acute representation of the angle\n",
    "  return result\n",
    "\n",
    "\n",
    "def get_standardized_angle(pose_angles):\n",
    "  average = sum(pose_angles) / len(pose_angles)\n",
    "  return round(average)\n",
    "\n",
    "def extract_angles(results):\n",
    "  if results.pose_landmarks is None:\n",
    "      return None\n",
    "  \n",
    "  # Calculates the essential angles for each image and adds them to the array\n",
    "  left_elbow_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST] , results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER])\n",
    "  right_elbow_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER])\n",
    "  left_shoulder_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP])\n",
    "  right_shoulder_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP])\n",
    "  left_hip_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE])\n",
    "  right_hip_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE])\n",
    "  left_knee_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HEEL])\n",
    "  right_knee_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HEEL])\n",
    "\n",
    "  golfdataset = pd.DataFrame([[left_elbow_angles, right_elbow_angles, left_shoulder_angles, right_shoulder_angles, left_hip_angles, left_knee_angles, left_knee_angles, right_knee_angles, 5]], columns=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', \"Label\"])\n",
    "  # golfdataset.to_csv('GolfMediaPipeData.csv', mode='a', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/59.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/111.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/223.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/226.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/311.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/502.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/618.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/701.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/702.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/792.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/1200.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/1237.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/1238.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Mid-Follow-Through/1369.jpg\n"
     ]
    }
   ],
   "source": [
    "# Set up Mediapipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Set minimum confidence levels\n",
    "min_detection_confidence = 0.5\n",
    "min_tracking_confidence = 0.5\n",
    "\n",
    "# Define the path to the directory containing the images\n",
    "image_dir = './GolfDB_Dataset/Mid-Follow-Through/'\n",
    "\n",
    "# Get a list of all the image filenames in the directory\n",
    "image_filenames = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir)\n",
    "                   if os.path.isfile(os.path.join(image_dir, filename))]\n",
    "\n",
    "# Sort the filenames in ascending order by their numeric value\n",
    "image_filenames = sorted(image_filenames, key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "\n",
    "ctr = 0\n",
    "# Loop over each image filename\n",
    "for filename in image_filenames:\n",
    "    # Read in the image\n",
    "    image = cv2.imread(filename)\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect the pose\n",
    "    with mp_pose.Pose(min_detection_confidence=min_detection_confidence,\n",
    "                      min_tracking_confidence=min_tracking_confidence) as pose:\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Check if pose_landmarks attribute is not found\n",
    "        if results.pose_landmarks is None:\n",
    "            print(f\"Pose landmarks not found in {filename}\")\n",
    "        else:\n",
    "            keypoints = extract_angles(results)\n",
    "            ctr+=1\n",
    "\n",
    "            # Get the height and width of the person in the image\n",
    "            height = int((results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image.shape[0]) -\n",
    "                        (results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP].y * image.shape[0]))\n",
    "            width = int((results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * image.shape[1]) -\n",
    "                        (results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * image.shape[1]))\n",
    "\n",
    "            # Calculate the aspect ratio and resize the image\n",
    "            aspect_ratio = width / height\n",
    "            if height > 160 or width > 160:\n",
    "                if height > width:\n",
    "                    new_height = 160\n",
    "                    new_width = int(new_height * aspect_ratio)\n",
    "                else:\n",
    "                    new_width = 160\n",
    "                    new_height = int(new_width / aspect_ratio)\n",
    "                image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "            # Draw all pose landmarks on the image\n",
    "            annotated_image = image.copy()\n",
    "            mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # Display the annotated image\n",
    "            cv2.imshow('Pose Detection', annotated_image)\n",
    "\n",
    "        if ctr >= 450:\n",
    "            break\n",
    "\n",
    "    # if cv2.waitKey(0) & 0xFF == ord('e'):\n",
    "    #     # cv2.destroyAllWindows()\n",
    "    #     break\n",
    "\n",
    "# Close the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173.382680</td>\n",
       "      <td>162.905673</td>\n",
       "      <td>1.682428</td>\n",
       "      <td>1.951471</td>\n",
       "      <td>157.318779</td>\n",
       "      <td>176.730082</td>\n",
       "      <td>176.730082</td>\n",
       "      <td>178.661229</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165.253038</td>\n",
       "      <td>156.930396</td>\n",
       "      <td>7.233925</td>\n",
       "      <td>1.591685</td>\n",
       "      <td>153.671720</td>\n",
       "      <td>173.217956</td>\n",
       "      <td>173.217956</td>\n",
       "      <td>177.346512</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161.581891</td>\n",
       "      <td>162.968698</td>\n",
       "      <td>3.535050</td>\n",
       "      <td>1.496108</td>\n",
       "      <td>169.982488</td>\n",
       "      <td>170.023857</td>\n",
       "      <td>170.023857</td>\n",
       "      <td>179.863322</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.232114</td>\n",
       "      <td>162.796697</td>\n",
       "      <td>0.613883</td>\n",
       "      <td>0.804719</td>\n",
       "      <td>173.916213</td>\n",
       "      <td>176.045937</td>\n",
       "      <td>176.045937</td>\n",
       "      <td>177.358669</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173.758449</td>\n",
       "      <td>175.173183</td>\n",
       "      <td>3.802594</td>\n",
       "      <td>0.828725</td>\n",
       "      <td>162.272318</td>\n",
       "      <td>174.503925</td>\n",
       "      <td>174.503925</td>\n",
       "      <td>171.857373</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          x1        x2        x3          x4          x5  \\\n",
       "0  173.382680  162.905673  1.682428  1.951471  157.318779  176.730082   \n",
       "1  165.253038  156.930396  7.233925  1.591685  153.671720  173.217956   \n",
       "2  161.581891  162.968698  3.535050  1.496108  169.982488  170.023857   \n",
       "3  169.232114  162.796697  0.613883  0.804719  173.916213  176.045937   \n",
       "4  173.758449  175.173183  3.802594  0.828725  162.272318  174.503925   \n",
       "\n",
       "           x6          x7  x8  Label  \n",
       "0  176.730082  178.661229   1    NaN  \n",
       "1  173.217956  177.346512   1    NaN  \n",
       "2  170.023857  179.863322   1    NaN  \n",
       "3  176.045937  177.358669   1    NaN  \n",
       "4  174.503925  171.857373   1    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"C:\\\\Users\\\\Crim\\\\Desktop\\\\RESEARCH_THESIS\\\\golfpose\\\\GolfMediaPipeData.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[173.38268005 162.90567338   1.68242825 ... 176.73008236 176.73008236\n",
      "  178.6612294 ]\n",
      " [165.25303778 156.93039561   7.23392467 ... 173.21795634 173.21795634\n",
      "  177.34651214]\n",
      " [161.5818915  162.96869754   3.5350505  ... 170.02385739 170.02385739\n",
      "  179.86332157]\n",
      " ...\n",
      " [177.53556858 153.62933603  11.0256545  ... 179.44972263 179.44972263\n",
      "  157.96385748]\n",
      " [173.92439152 169.73621312  21.28184849 ... 172.93674048 172.93674048\n",
      "  156.47654847]\n",
      " [151.75431044 147.30369408  34.05415923 ... 176.65252462 176.65252462\n",
      "  179.43459679]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('GolfMediaPipeData.csv' )\n",
    "X = df[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']]\n",
    "X = X.values\n",
    "print(X)\n",
    "y = df[['Label']]\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 2 5 5]\n",
      "Accuracy: 0.8026905829596412\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# initialize a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the data and transform it\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# initialize an SVM model with linear kernel\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "\n",
    "# fit the model to the scaled data\n",
    "clf.fit(X_scaled, y)\n",
    "\n",
    "# make predictions on the scaled data\n",
    "y_pred = clf.predict(X_scaled)\n",
    "\n",
    "print(y_pred)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 2 2 2 5 1 2 3 3 1 5 1 1 5 5 5 2 2 1 4 1 4 2 3 1 4 1 3 4 2 3 5 5 2 4 3\n",
      " 3 4 2 4 1 1 2 5 3 2 5 4 5 2 4 2 3 3 3 4 4 2 4 1 5 4 3 1 1 2 3 1 4 5 2 3 5\n",
      " 5 4 4 3 5 5 5 1 3 1 2 4 4 3 1 5 1 5 5 4 1 2 1 4 2 2 4 4 3 2 2 4 5 1 2 4 4\n",
      " 4 2 1 5 1 4 1 1 5 1 1 2 2 5 5 1 4 3 4 4 5 1 2 5 5 4 3 5 5 1 1 3 2 1 2 2 1\n",
      " 4 3 3 2 5 3 1 2 3 1 4 4 4 2 4 2 3 3 2 2 3 3 1 1 1 1 2 2 3 2 4 4 2 4 3 1 5\n",
      " 5 4 3 1 1 1 2 1 3 2 1 3 5 1 4 4 2 1 5 2 1 5 4 2 5 4 1 4 1 2 1 3 2 4 1 2 3\n",
      " 2 4 3 5 1 5 4 1 3 5 3 5 2 2 2 5 2 5 5 3 2 4 5 5 4 2 1 3 1 4 4 2 2 3 4 2 2\n",
      " 2 3 5 3 1 1 4 3 3 4 4 5 5 3 4 5 4 4 1 4 5 1 2 4 4 5 4 3 2 1 3 4 4 4 4 4 2\n",
      " 3 1 4 3 4 1 2 3 4 4 1 3 3 1 2 2 3 5 3 4 2 3 3 4 3 5 5 5 2 5 5 3 5 2 4 2 3\n",
      " 1 1 2 3 1 1 5 2 5 2 4 1 5 2 4 2 1 5 5 5 5 1 3 5 5 1 2 1 4 5 1 4 2 3 5 5 3\n",
      " 4 3 5 4 5 3 5 3 5 4 2 4 4 1 4 2 4 4 2 1 2 5 2 5 1 2 4 1 2 3 5 1 4 2 5 2 4\n",
      " 2 2 2 4 1 1 1 5 1 3 4 1 1 1 4 2 2 1 4 4 4 1 3 3 5 1 3 2 5 4 3 4 3 4 2 3 3\n",
      " 3 1]\n",
      "Accuracy: 0.7892376681614349\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# initialize a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# transform the test data using the scaler fitted to the training data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# initialize an SVM model with linear kernel\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "# fit the model to the scaled training data\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# make predictions on the scaled test data\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "print(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest confidence for label 0 : 4.312710191332661\n",
      "Highest confidence for label 1 : 4.3096315442480675\n",
      "Highest confidence for label 2 : 4.314458375911905\n",
      "Highest confidence for label 3 : 4.317306988215166\n",
      "Highest confidence for label 4 : 4.318833734344646\n"
     ]
    }
   ],
   "source": [
    "# obtain the decision function values for the test data\n",
    "decision_values = clf.decision_function(X_test_scaled)\n",
    "\n",
    "# find the index of the highest decision function value for each test sample\n",
    "max_indices = decision_values.argmax(axis=1)\n",
    "\n",
    "# get the corresponding class labels for the highest decision function values\n",
    "max_labels = clf.classes_[max_indices]\n",
    "\n",
    "# print the highest confidence level for each label\n",
    "for i in range(5):\n",
    "    max_confidence = decision_values[:,i][max_indices == i].max()\n",
    "    print(\"Highest confidence for label\", i, \":\", max_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m train_sizes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.1\u001b[39m, \u001b[39m1.0\u001b[39m, \u001b[39m20\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m train_sizes, train_scores, test_scores \u001b[39m=\u001b[39m learning_curve(\n\u001b[0;32m      3\u001b[0m     clf, X, y, train_sizes\u001b[39m=\u001b[39;49mtrain_sizes, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# calculate the mean and standard deviation of the training and validation scores\u001b[39;00m\n\u001b[0;32m      6\u001b[0m train_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(train_scores, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1579\u001b[0m, in \u001b[0;36mlearning_curve\u001b[1;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[0;32m   1576\u001b[0m     \u001b[39mfor\u001b[39;00m n_train_samples \u001b[39min\u001b[39;00m train_sizes_abs:\n\u001b[0;32m   1577\u001b[0m         train_test_proportions\u001b[39m.\u001b[39mappend((train[:n_train_samples], test))\n\u001b[1;32m-> 1579\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m   1580\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m   1581\u001b[0m         clone(estimator),\n\u001b[0;32m   1582\u001b[0m         X,\n\u001b[0;32m   1583\u001b[0m         y,\n\u001b[0;32m   1584\u001b[0m         scorer,\n\u001b[0;32m   1585\u001b[0m         train,\n\u001b[0;32m   1586\u001b[0m         test,\n\u001b[0;32m   1587\u001b[0m         verbose,\n\u001b[0;32m   1588\u001b[0m         parameters\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1589\u001b[0m         fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m   1590\u001b[0m         return_train_score\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1591\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m   1592\u001b[0m         return_times\u001b[39m=\u001b[39;49mreturn_times,\n\u001b[0;32m   1593\u001b[0m     )\n\u001b[0;32m   1594\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m train_test_proportions\n\u001b[0;32m   1595\u001b[0m )\n\u001b[0;32m   1596\u001b[0m results \u001b[39m=\u001b[39m _aggregate_score_dicts(results)\n\u001b[0;32m   1597\u001b[0m train_scores \u001b[39m=\u001b[39m results[\u001b[39m\"\u001b[39m\u001b[39mtrain_scores\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, n_unique_ticks)\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[1;32m--> 252\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[0;32m    253\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    317\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    319\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    321\u001b[0m (\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[0;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[0;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[0;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[0;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[0;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[0;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[1;32m--> 331\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    332\u001b[0m     X,\n\u001b[0;32m    333\u001b[0m     y,\n\u001b[0;32m    334\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[0;32m    335\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    336\u001b[0m     \u001b[39m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    337\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_class_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m, np\u001b[39m.\u001b[39;49mempty(\u001b[39m0\u001b[39;49m)),\n\u001b[0;32m    338\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[0;32m    339\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[0;32m    340\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    341\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    342\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    343\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    344\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    345\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[0;32m    346\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    347\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    348\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    349\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m    350\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[0;32m    351\u001b[0m )\n\u001b[0;32m    353\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sizes = np.linspace(0.1, 1.0, 20)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    clf, X, y, train_sizes=train_sizes, cv=5)\n",
    "\n",
    "# calculate the mean and standard deviation of the training and validation scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# plot the learning curve\n",
    "plt.plot(train_sizes, train_mean, label='Training score')\n",
    "plt.plot(train_sizes, test_mean, label='Cross-validation score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning curve for SVM with RBF kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_angles_test(results):\n",
    "  if results.pose_landmarks is None:\n",
    "      return None\n",
    "  \n",
    "  # Calculates the essential angles for each image and adds them to the array\n",
    "  left_elbow_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST] , results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER])\n",
    "  right_elbow_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER])\n",
    "  left_shoulder_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP])\n",
    "  right_shoulder_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP])\n",
    "  left_hip_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE])\n",
    "  right_hip_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE])\n",
    "  left_knee_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HEEL])\n",
    "  right_knee_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HEEL])\n",
    "\n",
    "  return [[left_elbow_angles, right_elbow_angles, left_shoulder_angles, right_shoulder_angles, left_hip_angles, right_hip_angles, left_knee_angles, right_knee_angles]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[171.82167871009224, 168.20648008727824, 6.981515830825712, 2.32970142952243, 157.42764786824966, 159.71238191553053, 174.02851029840014, 176.67957640486705]]\n",
      "Predicted label: 0, confidence: 90.02%\n",
      "[[168.22566303066594, 167.35876478613838, 7.849576095702405, 2.5038878448281814, 156.17630810795367, 160.4210417712123, 171.2040209569182, 176.17690388990206]]\n",
      "Predicted label: 0, confidence: 90.96%\n",
      "[[169.48910272832177, 168.13606641527429, 7.628018878527785, 3.117241423323473, 157.04535897816393, 159.64614214159784, 173.9238513986152, 176.92269886587647]]\n",
      "Predicted label: 0, confidence: 90.17%\n",
      "[[171.180769363857, 168.18164015810535, 7.065491704723987, 3.4129377802438166, 156.7452967749249, 160.7191082841294, 172.68788110151206, 173.62466031187893]]\n",
      "Predicted label: 0, confidence: 89.13%\n",
      "[[170.60110828069406, 168.7416955136977, 7.5051705119166, 5.3661523879664115, 155.494537853877, 160.19551076386065, 172.88861515101735, 176.35850607299798]]\n",
      "Predicted label: 0, confidence: 91.28%\n",
      "[[168.63104367253013, 166.13916483142188, 8.46649364726599, 4.963144561282852, 154.9733319612588, 159.95649022237612, 171.71280248877844, 177.37647933773417]]\n",
      "Predicted label: 0, confidence: 91.49%\n",
      "[[165.27472787416434, 161.53660628952446, 9.013584666913385, 3.2048667628025904, 154.81683983234788, 160.42230121749992, 174.5927303260112, 177.53825283492085]]\n",
      "Predicted label: 0, confidence: 91.27%\n",
      "[[172.94597422744465, 163.0621897083871, 4.254678189985779, 7.088397508776643, 156.51290617637645, 161.2439937989511, 177.0563404227371, 176.09188898190666]]\n",
      "Predicted label: 0, confidence: 88.02%\n",
      "[[167.24379766665044, 157.52408511771205, 6.019958961120465, 3.625644031935764, 156.88377130585454, 159.12271884561227, 176.3475516155286, 176.48475132036342]]\n",
      "Predicted label: 0, confidence: 86.82%\n",
      "[[164.24271749859756, 160.96892271837476, 6.714228819866086, 1.6352526550832545, 155.88363190897616, 159.4419942183488, 175.17552257142762, 176.4621936212823]]\n",
      "Predicted label: 0, confidence: 90.41%\n",
      "[[163.79426416192348, 157.03460142708494, 7.718003194363602, 0.9873004581937737, 155.93450763417113, 160.69995068595907, 174.79836061783965, 177.29704228836448]]\n",
      "Predicted label: 0, confidence: 89.57%\n",
      "[[164.18925938867076, 156.16958372532739, 9.275449494634435, 0.4121638477572867, 155.3050800348579, 161.80296533190983, 174.0677418920494, 177.00740612125378]]\n",
      "Predicted label: 0, confidence: 90.01%\n",
      "[[167.22155178088957, 164.26094384343943, 7.628633816175493, 3.043643672362318, 154.9669565886076, 159.29079900901354, 173.45555380081692, 178.87431315240084]]\n",
      "Predicted label: 0, confidence: 92.47%\n",
      "[[163.14887031059033, 163.77132545075972, 9.898629814251876, 3.1544943016123606, 155.5609291625308, 158.83187938017406, 173.93389108418583, 179.51056876767814]]\n",
      "Predicted label: 0, confidence: 91.30%\n",
      "[[166.01677260901437, 166.05308575409185, 7.435612192174786, 3.3322355568773188, 156.13693365020293, 160.70782301976385, 172.9053005398574, 177.42920560112879]]\n",
      "Predicted label: 0, confidence: 91.01%\n",
      "[[170.38392743457368, 166.35519140295457, 4.326892216237629, 4.3764338993680045, 154.2184935677585, 159.7126620417234, 170.24622534863255, 179.83007326139108]]\n",
      "Predicted label: 0, confidence: 93.99%\n",
      "[[168.00789431477014, 164.19929856195708, 5.198444087334507, 3.1866648410343235, 154.98535160179492, 160.22488564190587, 169.71841143876657, 178.48088501704575]]\n",
      "Predicted label: 0, confidence: 92.61%\n",
      "[[164.65272370847345, 164.95645032624896, 7.636389997176032, 3.7148323543628945, 154.78251677261702, 159.41463076159368, 171.41596983543488, 179.12563383170942]]\n",
      "Predicted label: 0, confidence: 92.62%\n",
      "[[168.72047276549546, 166.1743916848421, 6.055563147242741, 3.839630258710443, 155.23922803352377, 158.45464279410535, 171.8749106986191, 179.46488587981673]]\n",
      "Predicted label: 0, confidence: 92.72%\n",
      "[[164.35263348302433, 165.27428224445146, 7.129449318004464, 4.2557117625035605, 153.80054278189408, 159.2261773154227, 170.62912656952352, 179.1686771286132]]\n",
      "Predicted label: 0, confidence: 93.60%\n",
      "[[158.681681096272, 162.48659298536955, 9.410860565341002, 3.7178210850036644, 153.92843135545905, 158.5077186814389, 170.92404657672904, 179.34756078428387]]\n",
      "Predicted label: 0, confidence: 92.64%\n",
      "[[156.92058052217945, 163.08091309374194, 10.695418008913512, 2.1338322862477783, 155.9798074818531, 157.4647984059779, 173.90653557622636, 179.47604596661407]]\n",
      "Predicted label: 0, confidence: 90.74%\n",
      "[[165.15737713306575, 163.45234257630258, 7.329728749816945, 2.438189680422287, 152.39580522843525, 159.18315998664463, 169.1942347366695, 179.13736890277522]]\n",
      "Predicted label: 0, confidence: 94.88%\n",
      "[[164.80179660738753, 164.95538690916234, 6.063783312706604, 2.643235963248536, 156.37768091666177, 157.94904293443386, 174.29212700608613, 179.30492063586175]]\n",
      "Predicted label: 0, confidence: 91.57%\n",
      "[[173.55968491868055, 167.27994700122875, 0.9927895357134577, 5.460396916990941, 157.5301123387938, 157.17435985313193, 174.74699394390345, 177.6714678922962]]\n",
      "Predicted label: 0, confidence: 89.93%\n",
      "[[174.18665141882872, 169.53022360154918, 0.3033813292566862, 7.019852065358626, 159.14194218257825, 157.46291928631317, 178.75205545771456, 177.38569103633841]]\n",
      "Predicted label: 0, confidence: 87.63%\n",
      "[[177.8564294138671, 172.44829925137347, 1.1018525632898242, 6.657404559506801, 158.8113464652077, 158.4256267810037, 177.5299853148782, 177.5907585339278]]\n",
      "Predicted label: 0, confidence: 89.20%\n",
      "[[174.29138134428143, 169.56184814870855, 0.4604641244553459, 5.482280447240946, 158.98032530437266, 157.0052126749408, 177.72017920951205, 178.79749223909113]]\n",
      "Predicted label: 0, confidence: 89.24%\n",
      "[[171.96266926882814, 164.28297718864246, 1.9197602638316293, 1.555322042134684, 159.11164943271748, 157.7677705296926, 179.07424051438886, 177.90255689883645]]\n",
      "Predicted label: 0, confidence: 88.44%\n",
      "[[173.69950003257006, 163.37048543491866, 0.9715621943728785, 1.5746385200447837, 157.55117188182118, 157.59291628445303, 175.987946872299, 178.23730025945878]]\n",
      "Predicted label: 0, confidence: 90.67%\n",
      "[[170.92975635725142, 170.5388494440521, 1.8867466926114984, 5.1292056457615, 158.67249550041313, 157.88645645253231, 177.10525707887473, 177.45552651407405]]\n",
      "Predicted label: 0, confidence: 89.30%\n",
      "[[168.62180997831928, 168.51061636292667, 3.044452889549464, 4.893348646564066, 157.0206899524208, 158.7876688867, 176.30871193415857, 177.03052008653327]]\n",
      "Predicted label: 0, confidence: 90.77%\n",
      "[[169.66104612081656, 166.2337274755744, 1.9799281174651608, 2.9745066152089406, 158.86305015274456, 157.6037541645937, 177.5056916819853, 179.52142123337265]]\n",
      "Predicted label: 0, confidence: 89.50%\n",
      "[[172.26064006155656, 164.01494034183847, 1.799298145310549, 3.010269547003421, 159.10386389496625, 160.6384239979904, 178.47649937275335, 174.8788189211491]]\n",
      "Predicted label: 0, confidence: 86.09%\n",
      "[[161.9859811557714, 153.63253264052813, 2.427112918765362, 2.4118018361004228, 158.12769399270815, 158.01184515117643, 178.80260151367557, 178.92397145059113]]\n",
      "Predicted label: 0, confidence: 86.16%\n",
      "[[162.12589272010987, 169.11166560347576, 0.25323446027215, 0.5201008133561565, 156.51501939758924, 156.63025800837514, 174.61696366664728, 178.94008631388385]]\n",
      "Predicted label: 0, confidence: 93.82%\n",
      "[[177.4389531568128, 171.74956541618522, 0.8812071479318071, 3.4694366939801333, 155.61611929822308, 160.4334780676215, 177.17390413613808, 175.90106576088814]]\n",
      "Predicted label: 0, confidence: 93.73%\n",
      "[[162.85340254700432, 172.06419013468184, 2.6861512348493917, 7.53188203052741, 157.27134057122376, 158.24404985767214, 177.3086804638047, 179.4744165168326]]\n",
      "Predicted label: 0, confidence: 91.42%\n",
      "[[152.1761624024679, 155.30492985056583, 3.8395717788281356, 17.364032212360065, 158.0979851260062, 156.69941831209923, 175.18686174990415, 177.04797204688253]]\n",
      "Predicted label: 0, confidence: 73.04%\n",
      "[[141.64869971131628, 167.83673636376867, 4.815630137606778, 21.535077273801175, 158.3691701254916, 156.70725797322044, 172.68455401045765, 173.78649733190227]]\n",
      "Predicted label: 0, confidence: 73.18%\n",
      "[[132.50436658007172, 177.3173917781762, 12.596631195802317, 17.434844384467564, 161.44655861439747, 155.00675297974743, 177.6870917726346, 171.85442256177768]]\n",
      "Predicted label: 0, confidence: 67.68%\n",
      "[[161.4888549800631, 178.05305850580493, 16.233404188767874, 29.890977875290666, 159.63394190364085, 155.40408091999146, 174.62799630886627, 172.0982085232281]]\n",
      "Predicted label: 0, confidence: 49.52%\n",
      "[[134.09478023879947, 173.66956016242713, 20.527703003804145, 32.060367718837064, 161.85543566086935, 155.45489634263353, 178.06775395786903, 173.4982407058659]]\n",
      "Predicted label: 0, confidence: 32.80%\n",
      "[[124.49928463629553, 164.55830123891243, 20.135295592491527, 34.7695838765854, 161.98369467524282, 154.8403785800894, 177.78963233250116, 171.83279306171775]]\n",
      "Predicted label: 1, confidence: 33.51%\n",
      "[[137.3378316634961, 166.74311948202595, 0.026124975418860788, 33.9881359137799, 161.61822115416646, 157.1598102687803, 174.2054244830239, 173.52162430436906]]\n",
      "Predicted label: 0, confidence: 48.08%\n",
      "[[144.29434323919236, 129.78342690197357, 1.5747747475476115, 26.871019862331277, 162.30303786758643, 159.6386189952751, 174.39545158259747, 173.43914767370018]]\n",
      "Predicted label: 1, confidence: 61.51%\n",
      "[[169.48093128456247, 123.26453648430969, 5.441728178049073, 40.90722664412182, 163.5701272032345, 156.57661127287122, 175.42376619843517, 173.3946506299624]]\n",
      "Predicted label: 4, confidence: 48.40%\n",
      "[[178.31352490493907, 138.28168755779814, 7.522153966921871, 53.70019997896687, 162.47234376120096, 158.60846560942835, 174.9335722992797, 175.26251462281434]]\n",
      "Predicted label: 4, confidence: 80.16%\n",
      "[[130.7365572597943, 122.79027447234684, 18.895712886704853, 48.29894030829594, 161.98015809092013, 161.50769744190438, 173.94346620721316, 173.7130355523715]]\n",
      "Predicted label: 4, confidence: 31.58%\n",
      "[[130.7456248272635, 133.37703333026764, 11.37192454940046, 66.98375447554857, 161.65234565886962, 160.756213746181, 173.48347136342514, 173.33624618299]]\n",
      "Predicted label: 4, confidence: 37.38%\n",
      "[[129.46915030171604, 132.73470844573828, 5.868078638071163, 74.3042386236296, 161.73869656242292, 159.2393836361185, 173.7809921795822, 172.29954521189765]]\n",
      "Predicted label: 4, confidence: 40.57%\n",
      "[[91.52575235213168, 134.60778048680174, 6.590966977195173, 93.97884508863613, 164.882600439294, 158.4963277011101, 176.5648942400325, 173.56381305805925]]\n",
      "Predicted label: 3, confidence: 49.55%\n",
      "[[143.84636454787852, 98.05778395776849, 5.228298659130754, 81.96680998590682, 162.13610411561413, 161.0176693804542, 177.0653465901, 175.9465708255699]]\n",
      "Predicted label: 4, confidence: 41.59%\n",
      "[[93.66059983866548, 110.02642197607189, 25.69886990307676, 93.775657697204, 163.88358320847342, 161.0415990598008, 178.93265902329745, 173.53096598928687]]\n",
      "Predicted label: 3, confidence: 52.00%\n",
      "[[97.22986456556889, 140.66313106159873, 7.400890665192496, 119.32261680945948, 164.41729219286702, 160.36598540522505, 179.84247096798762, 171.75722750786]]\n",
      "Predicted label: 2, confidence: 56.13%\n",
      "[[68.75707762259921, 136.36395754116245, 0.5439070578684448, 126.12914292057044, 165.42561018907708, 160.82695390230236, 178.51661088563424, 172.71514618921734]]\n",
      "Predicted label: 2, confidence: 52.00%\n",
      "[[115.82584173383705, 139.55658603397114, 126.13084387139091, 126.67728767648327, 166.11171156135586, 174.32055051039382, 176.57901542095706, 162.66539860866777]]\n",
      "Predicted label: 2, confidence: 81.57%\n",
      "[[83.63206890593077, 92.3104284401312, 55.235388765571194, 118.71796575742468, 167.52177752336846, 162.0105497391592, 177.63964525856122, 172.57735746799995]]\n",
      "Predicted label: 3, confidence: 64.51%\n",
      "[[113.48629763367693, 129.41254167175475, 94.50388843761391, 146.20460724027035, 169.48825587381916, 165.52391106694682, 178.64767222671028, 172.3778626938521]]\n",
      "Predicted label: 2, confidence: 50.16%\n",
      "[[118.24555035731693, 120.2366782600655, 97.0924453815428, 153.70895878729058, 169.61105156758035, 160.12674976427232, 179.71684793910256, 170.97594663910488]]\n",
      "Predicted label: 3, confidence: 59.50%\n",
      "[[155.84928608786367, 124.49599264598992, 119.64313325051504, 150.10026690894074, 170.59945813184302, 158.1904528047443, 179.20247526557225, 170.19211507207586]]\n",
      "Predicted label: 3, confidence: 63.34%\n",
      "[[71.67740221575865, 119.70430857340818, 44.237892509680535, 135.6154616969156, 169.85701157531352, 157.40851734208724, 176.6868418440433, 169.22657910080545]]\n",
      "Predicted label: 3, confidence: 64.06%\n",
      "[[59.23402609754, 117.81078908936227, 1.5449219473610212, 134.77486782451672, 172.7551717941129, 150.20473805170278, 175.50677333729223, 170.65841376604882]]\n",
      "Predicted label: 3, confidence: 80.24%\n",
      "[[69.37428950652757, 87.20184763879804, 15.233279974327592, 76.34858138299948, 174.41429357983532, 146.32191770396278, 177.21526003375408, 172.94257585277407]]\n",
      "Predicted label: 3, confidence: 87.02%\n",
      "[[66.89910176252117, 41.298410034756145, 23.793027164646865, 26.547938660281666, 175.5210064967034, 149.82740978497083, 177.60480896778876, 178.4186103629972]]\n",
      "Predicted label: 3, confidence: 83.92%\n",
      "[[123.29986709073697, 176.03697103378207, 2.943500344394092, 16.785259782556846, 170.3908241836687, 149.43296924119377, 174.20224679780935, 175.83465227452993]]\n",
      "Predicted label: 1, confidence: 54.33%\n",
      "[[124.98851040980946, 168.68750652577444, 5.741168374411487, 9.46561750504835, 175.24524818129967, 145.74670350606146, 174.92139577299938, 170.680691867028]]\n",
      "Predicted label: 1, confidence: 77.90%\n",
      "[[165.7068167288978, 152.44470085982266, 5.119215957997064, 0.22901097323343775, 177.70072407692186, 145.26277310310613, 174.8668492009042, 167.76489923269716]]\n",
      "Predicted label: 1, confidence: 85.48%\n",
      "[[174.63980597685892, 159.6545582143179, 13.013752753580354, 12.130716233866622, 179.2681122754061, 143.98034363570125, 175.3710988558581, 167.01046838040108]]\n",
      "Predicted label: 1, confidence: 65.53%\n",
      "[[160.124769602996, 135.44250717266317, 26.92952990323302, 17.623278337320578, 179.6794689817419, 145.50043258481645, 175.95638380344425, 170.23125673548608]]\n",
      "Predicted label: 4, confidence: 56.10%\n",
      "[[162.83591410768443, 143.57164634688237, 60.97171925200142, 21.161788754073793, 179.70605441020456, 145.56178868427233, 172.03742757068332, 167.31468926484263]]\n",
      "Predicted label: 3, confidence: 51.47%\n",
      "[[170.0467720986552, 162.3158765551108, 95.02517458822668, 24.748221370996223, 175.05487526351024, 148.34688723761025, 171.77247112833706, 164.62608642514223]]\n",
      "Predicted label: 3, confidence: 59.13%\n",
      "[[169.81664422892214, 176.40824882769977, 113.69312057759777, 115.42081317592181, 170.98225793928586, 150.2915439501473, 170.5336027732372, 154.21514978039673]]\n",
      "Predicted label: 2, confidence: 50.49%\n",
      "[[151.91136803708892, 168.91543621498164, 138.04554868999216, 128.48093191496793, 175.2764684162035, 158.32135521587728, 174.88285774865594, 152.55444196627428]]\n",
      "Predicted label: 2, confidence: 67.18%\n",
      "[[162.88128102828688, 159.95352888132732, 131.93407748843222, 131.89831375170914, 175.23799155711583, 165.00287442756724, 179.32106114721722, 149.1000004310255]]\n",
      "Predicted label: 2, confidence: 83.97%\n",
      "[[153.11235790805318, 157.1204922981435, 148.3939256166549, 137.10980315649786, 167.0744894302177, 167.08788705045728, 176.66653549116367, 139.95048037838535]]\n",
      "Predicted label: 2, confidence: 92.85%\n",
      "[[48.23991034092707, 116.33976599454627, 80.01700901187526, 14.705488525409043, 174.80742600057945, 168.6975798633917, 170.3609479768988, 139.4044684901078]]\n",
      "Predicted label: 2, confidence: 54.82%\n",
      "[[175.0821662482677, 39.81963963127938, 3.061119390194123, 33.74026516229937, 171.89187903899673, 168.59650187354822, 177.57770247162986, 145.67468447398255]]\n",
      "Predicted label: 4, confidence: 53.06%\n",
      "[[173.10463800717582, 154.0154910708539, 1.730454299788342, 159.3319617023579, 171.99722049166311, 163.45093177888236, 177.0371004819491, 147.5550630560622]]\n",
      "Predicted label: 4, confidence: 98.02%\n",
      "[[70.28745239889064, 129.4083143620122, 1.7438701624761839, 11.723998008174958, 174.6618491183972, 168.83966482301548, 177.657692786903, 147.18439461167128]]\n",
      "Predicted label: 1, confidence: 97.24%\n",
      "[[172.06608736765375, 148.50632877677697, 1.4657590283295916, 5.3108513473002805, 172.85077817992013, 171.34572862653633, 165.95254628406124, 158.66184604659404]]\n",
      "Predicted label: 1, confidence: 84.20%\n",
      "[[150.48356322217322, 165.69073102647783, 8.780712032453074, 164.75944049109503, 175.3496988069237, 160.0073430668786, 171.71733229034697, 153.24393578167982]]\n",
      "Predicted label: 4, confidence: 71.26%\n",
      "[[30.91187914307687, 161.95822623026356, 22.525299248341295, 165.20799398818687, 172.32238010102492, 157.7921902459096, 176.50007763453615, 152.9003117941841]]\n",
      "Predicted label: 2, confidence: 71.51%\n",
      "[[81.03466036219396, 130.56041611295893, 16.260793364910494, 123.70518308404979, 175.83288622565792, 160.7047285229837, 179.50154797973576, 156.2284460757808]]\n",
      "Predicted label: 2, confidence: 64.66%\n",
      "[[136.04732515287517, 76.25518106517202, 2.539958598259925, 101.63863133644725, 171.43736891753232, 159.80242834547968, 175.62816462255847, 151.13362192562278]]\n",
      "Predicted label: 4, confidence: 68.87%\n",
      "[[175.454264533137, 99.95622999208774, 4.495755765923948, 108.64861437447126, 174.60106301160062, 167.7964590656472, 176.76516371869337, 152.41603664985493]]\n",
      "Predicted label: 4, confidence: 97.34%\n",
      "[[162.71456365456106, 74.50152019875043, 3.3804276329668586, 95.93954025818954, 166.98675787168906, 161.7373630262288, 174.69159202221448, 150.2257555658332]]\n",
      "Predicted label: 4, confidence: 93.67%\n",
      "[[156.7128028571122, 35.20447427488268, 22.79061350623202, 77.59667748134567, 170.39871332699016, 169.11725774685846, 176.75031817430533, 138.7994373938597]]\n",
      "Predicted label: 4, confidence: 92.36%\n",
      "[[171.088262399618, 84.49096715093577, 9.447659549536647, 93.42112313814712, 165.17598100946836, 165.16982662022713, 174.32245616805054, 142.24924350984594]]\n",
      "Predicted label: 4, confidence: 98.44%\n",
      "[[7.286438950911047, 137.80474705277467, 56.44718954503821, 147.32797500001516, 174.6350051048329, 161.39296372868415, 174.46125494598266, 158.51098498498942]]\n",
      "Predicted label: 2, confidence: 56.41%\n",
      "[[164.33135432834166, 154.1162330176547, 1.3952492183045277, 70.619560195306, 178.7687334741197, 166.77221435252358, 170.6108273924753, 151.84819069339227]]\n",
      "Predicted label: 4, confidence: 89.44%\n",
      "[[177.2446631640917, 145.03944447588378, 6.287568596798942, 112.03208806655456, 169.34573959114545, 160.91486948166474, 173.35734716734603, 156.01189129797945]]\n",
      "Predicted label: 4, confidence: 97.50%\n",
      "[[179.70998045768812, 113.25472827804452, 7.529345184621055, 78.85293436422936, 175.89568255794418, 167.02782882713657, 177.52169788746622, 161.36182233901536]]\n",
      "Predicted label: 4, confidence: 96.86%\n",
      "[[12.389366186772888, 161.7704748111992, 0.22649550621735712, 130.7882849744994, 179.77779015742095, 170.80567548487892, 172.00163413690834, 160.0127664401956]]\n",
      "Predicted label: 2, confidence: 69.64%\n",
      "[[75.18747959853188, 7.057165424048806, 81.69463013186348, 17.067739146394874, 157.49593095460773, 170.21180313689067, 171.52663552432836, 178.28543753491863]]\n",
      "Predicted label: 3, confidence: 75.80%\n",
      "[[45.795800327110335, 167.34635237958395, 19.103567528343834, 179.07258725643507, 165.60244996375522, 176.22159841725664, 149.69314940319347, 177.1450661285135]]\n",
      "Predicted label: 3, confidence: 72.51%\n",
      "[[42.07060796490071, 116.14465650168711, 8.420502514935057, 113.44018225517374, 169.4641092153379, 178.44437942982046, 169.6204521815569, 163.1779521599526]]\n",
      "Predicted label: 2, confidence: 71.82%\n",
      "[[177.0094965532833, 174.43732864386712, 173.22247141962973, 174.14701624959483, 173.62318646717955, 174.8048079573053, 168.50959656456308, 161.2821450388203]]\n",
      "Predicted label: 2, confidence: 70.31%\n",
      "[[167.97681342186596, 170.72900669357705, 174.67265435222276, 178.4671701100344, 162.34494771770292, 167.48002943543366, 153.83018989091724, 178.69402919385496]]\n",
      "Predicted label: 3, confidence: 81.28%\n",
      "[[176.41558097033754, 157.90063744807577, 166.54418961723724, 138.3422807036398, 176.94368075712924, 168.4471090152078, 172.0702220450609, 151.92513504087097]]\n",
      "Predicted label: 2, confidence: 73.23%\n",
      "[[175.68275529229368, 162.3814536127928, 160.2110771240627, 150.30375702926932, 173.16972461430103, 176.0957864537018, 174.24640859813104, 163.3675985749887]]\n",
      "Predicted label: 2, confidence: 76.97%\n",
      "[[153.3667454088172, 134.20981115542662, 149.07537224083813, 129.88797080695133, 179.25713207339638, 171.8400212640246, 174.57278586020126, 163.45459242118326]]\n",
      "Predicted label: 2, confidence: 57.80%\n",
      "[[157.77879603797518, 147.16002512864583, 128.63516648185933, 126.76107980469277, 165.8237069681087, 159.9644030032548, 175.72980255628454, 155.13313614865334]]\n",
      "Predicted label: 2, confidence: 71.57%\n",
      "[[153.3718831231766, 158.12266401441988, 126.91524297219154, 124.25300582559213, 170.33950199005778, 161.39874544696653, 179.25601306785703, 158.15830236202564]]\n",
      "Predicted label: 2, confidence: 73.75%\n",
      "[[121.78837257413525, 117.26693768370254, 107.99199541703952, 106.97077449631475, 163.49865753446846, 160.32264725835398, 175.58098376734426, 156.72058105091827]]\n",
      "Predicted label: 2, confidence: 65.85%\n",
      "[[119.4934553420251, 124.32726229170191, 96.32415267476749, 94.91918586399949, 161.7313049273701, 160.48808234938173, 169.9761462587537, 154.79256732456173]]\n",
      "Predicted label: 2, confidence: 64.64%\n",
      "[[141.48780228686437, 145.75665868142173, 112.6780713856389, 106.25206685026599, 166.75314683466883, 163.0234524971421, 176.05072379793774, 150.80619826427062]]\n",
      "Predicted label: 2, confidence: 81.58%\n",
      "[[130.68121070120063, 150.48606386988712, 105.80007599177195, 100.7097321272901, 161.84986271833105, 159.5982288245354, 169.67782238415697, 156.65436918127344]]\n",
      "Predicted label: 2, confidence: 66.75%\n",
      "[[134.01739802014617, 134.56932569985096, 86.17486316557346, 95.966854504206, 171.1069262035756, 162.62598185972584, 177.3909920824568, 158.93117747511408]]\n",
      "Predicted label: 2, confidence: 67.16%\n",
      "[[141.5222108499619, 130.3137414987304, 89.36229171589854, 83.6991495814698, 164.32091195923928, 160.55783558988995, 173.06056047275231, 157.91000559340748]]\n",
      "Predicted label: 2, confidence: 64.43%\n",
      "[[143.43773843395053, 131.49182173866149, 91.80912880094203, 83.84981830820107, 162.70930981779154, 159.2915701417106, 170.2975410978772, 159.96172008196635]]\n",
      "Predicted label: 2, confidence: 56.26%\n",
      "[[142.18530502509813, 136.12882599764993, 91.3704166246605, 84.33761278846055, 162.1304594384953, 156.93874205413087, 170.95762055807376, 162.9928300060782]]\n",
      "Predicted label: 2, confidence: 50.42%\n",
      "[[149.4121441111343, 148.3870165945535, 87.87218538170069, 85.42559974039874, 162.3696131091433, 155.7795807875026, 171.71465679457017, 163.5238297784975]]\n",
      "Predicted label: 2, confidence: 52.11%\n",
      "[[149.3830090523726, 142.9119656108458, 80.86962997899663, 79.79052437193774, 165.33176946988328, 160.2109124028875, 172.9061867683641, 158.85609129240044]]\n",
      "Predicted label: 2, confidence: 63.52%\n",
      "Label 0 has highest confidence level of 94.88%\n",
      "Label 1 has highest confidence level of 97.24%\n",
      "Label 4 has highest confidence level of 98.44%\n",
      "Label 3 has highest confidence level of 87.02%\n",
      "Label 2 has highest confidence level of 92.85%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Set up Mediapipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Set minimum confidence levels\n",
    "min_detection_confidence = 0.5\n",
    "min_tracking_confidence = 0.5\n",
    "\n",
    "# Define the path to the video file\n",
    "video_file = './8.mp4'\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "# Initialize dictionary to store highest confidence level frame for each predicted label\n",
    "highest_conf_frames = {}\n",
    "\n",
    "# Loop over each frame of the video\n",
    "while cap.isOpened():\n",
    "    # Read in the frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect the pose\n",
    "    with mp_pose.Pose(min_detection_confidence=min_detection_confidence,\n",
    "                      min_tracking_confidence=min_tracking_confidence) as pose:\n",
    "        results = pose.process(frame)\n",
    "        test_value = extract_angles_test(results)\n",
    "        print(test_value)\n",
    "        test_scaled_value = scaler.transform(test_value)\n",
    "        test_probabilities = clf.predict_proba(test_scaled_value)\n",
    "        test_prediction = np.argmax(test_probabilities)\n",
    "        test_confidence = test_probabilities[0][test_prediction] * 100\n",
    "        print(f\"Predicted label: {test_prediction}, confidence: {test_confidence:.2f}%\")\n",
    "\n",
    "        # Check if pose_landmarks attribute is not found or does not contain all expected landmarks\n",
    "        if not results.pose_landmarks or len(results.pose_landmarks.landmark) != 33:\n",
    "            continue\n",
    "\n",
    "        # Draw the pose landmarks on the image\n",
    "        annotated_image = frame.copy()\n",
    "\n",
    "        # Check if current frame has highest confidence level for predicted label\n",
    "        if test_prediction not in highest_conf_frames or test_confidence > highest_conf_frames[test_prediction][0]:\n",
    "            # Update dictionary with current frame as new highest confidence level frame\n",
    "            highest_conf_frames[test_prediction] = (test_confidence, annotated_image)\n",
    "\n",
    "    # Display the annotated image\n",
    "    cv2.imshow('Pose Detection', annotated_image)\n",
    "\n",
    "    # Exit the loop when the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Display the highest confidence level frames for each predicted label\n",
    "for label, (confidence, frame) in highest_conf_frames.items():\n",
    "    print(f\"Label {label} has highest confidence level of {confidence:.2f}%\")\n",
    "    cv2.imshow(f\"Label {label}\", frame)\n",
    "    cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
