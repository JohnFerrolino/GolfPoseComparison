{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapipe as mp\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "pose = mp_pose.Pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def calculate_angles(firstPoint, midPoint, lastPoint):\n",
    "  result = math.degrees(math.atan2(lastPoint.y  - midPoint.y, lastPoint.x - midPoint.x) - math.atan2(firstPoint.y - midPoint.y, firstPoint.x - midPoint.x))\n",
    "  result = abs(result)\n",
    "  if result > 180:\n",
    "      result = 360.0 - result\n",
    "  return result\n",
    "\n",
    "\n",
    "def get_standardized_angle(pose_angles):\n",
    "  average = sum(pose_angles) / len(pose_angles)\n",
    "  return round(average)\n",
    "\n",
    "def extract_angles(results):\n",
    "  if results.pose_landmarks is None:\n",
    "      return None\n",
    "  \n",
    "  # Calculates the essential angles for each image and adds them to the array\n",
    "  left_elbow_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST] , results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER])\n",
    "  right_elbow_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER])\n",
    "  left_shoulder_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP])\n",
    "  right_shoulder_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP])\n",
    "  left_hip_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE])\n",
    "  right_hip_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE])\n",
    "  left_knee_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HEEL])\n",
    "  right_knee_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HEEL])\n",
    "\n",
    "  golfdataset = pd.DataFrame([[left_elbow_angles, right_elbow_angles, left_shoulder_angles, right_shoulder_angles, left_hip_angles, right_hip_angles, left_knee_angles, right_knee_angles, 5]], columns=['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', \"Label\"])\n",
    "  #golfdataset.to_csv('GolfMediaPipeData.csv', mode='a', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/20.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/21.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/59.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/204.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/223.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/226.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/281.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/409.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/439.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/498.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/503.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/512.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/618.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/701.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/797.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/822.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/1166.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/1199.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/1200.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/1237.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/1304.jpg\n",
      "Pose landmarks not found in ./GolfDB_Dataset/Impact/1369.jpg\n",
      "Successfully captured all pose landmarks in 446 out of 468 images.\n",
      "Skipped 22 images.\n"
     ]
    }
   ],
   "source": [
    "# Set up Mediapipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "min_detection_confidence = 0.5\n",
    "min_tracking_confidence = 0.5\n",
    "\n",
    "image_dir = './GolfDB_Dataset/Impact/'\n",
    "image_filenames = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir)\n",
    "                   if os.path.isfile(os.path.join(image_dir, filename))]\n",
    "image_filenames = sorted(image_filenames, key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "\n",
    "ctr = 0\n",
    "success_ctr = 0\n",
    "skipped_ctr = 0\n",
    "\n",
    "for filename in image_filenames:\n",
    "\n",
    "    image = cv2.imread(filename)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect the pose\n",
    "    with mp_pose.Pose(min_detection_confidence=min_detection_confidence,\n",
    "                      min_tracking_confidence=min_tracking_confidence) as pose:\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if results.pose_landmarks is None:\n",
    "            print(f\"Pose landmarks not found in {filename}\")\n",
    "            skipped_ctr += 1\n",
    "        else:\n",
    "            keypoints = extract_angles(results)\n",
    "            success_ctr += 1\n",
    "            ctr += 1\n",
    "\n",
    "            annotated_image = image.copy()\n",
    "            mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # Display the annotated image\n",
    "            cv2.imshow('Pose Detection', annotated_image)\n",
    "\n",
    "        # if ctr >= 450:\n",
    "        #     break\n",
    "\n",
    "    # if cv2.waitKey(0) & 0xFF == ord('e'):\n",
    "    #     # cv2.destroyAllWindows()\n",
    "    #     break\n",
    "\n",
    "print(f\"Successfully captured all pose landmarks in {success_ctr} out of {ctr + skipped_ctr} images.\")\n",
    "print(f\"Skipped {skipped_ctr} images.\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173.382680</td>\n",
       "      <td>162.905673</td>\n",
       "      <td>1.682428</td>\n",
       "      <td>1.951471</td>\n",
       "      <td>157.318779</td>\n",
       "      <td>158.426863</td>\n",
       "      <td>176.730082</td>\n",
       "      <td>178.661229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165.253038</td>\n",
       "      <td>156.930396</td>\n",
       "      <td>7.233925</td>\n",
       "      <td>1.591685</td>\n",
       "      <td>153.671720</td>\n",
       "      <td>160.914156</td>\n",
       "      <td>173.217956</td>\n",
       "      <td>177.346512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161.581891</td>\n",
       "      <td>162.968698</td>\n",
       "      <td>3.535050</td>\n",
       "      <td>1.496108</td>\n",
       "      <td>169.982488</td>\n",
       "      <td>156.329636</td>\n",
       "      <td>170.023857</td>\n",
       "      <td>179.863322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169.232114</td>\n",
       "      <td>162.796697</td>\n",
       "      <td>0.613883</td>\n",
       "      <td>0.804719</td>\n",
       "      <td>173.916213</td>\n",
       "      <td>154.806477</td>\n",
       "      <td>176.045937</td>\n",
       "      <td>177.358669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173.758449</td>\n",
       "      <td>175.173183</td>\n",
       "      <td>3.802594</td>\n",
       "      <td>0.828725</td>\n",
       "      <td>162.272318</td>\n",
       "      <td>157.735769</td>\n",
       "      <td>174.503925</td>\n",
       "      <td>171.857373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          x2        x3        x4          x5          x6  \\\n",
       "0  173.382680  162.905673  1.682428  1.951471  157.318779  158.426863   \n",
       "1  165.253038  156.930396  7.233925  1.591685  153.671720  160.914156   \n",
       "2  161.581891  162.968698  3.535050  1.496108  169.982488  156.329636   \n",
       "3  169.232114  162.796697  0.613883  0.804719  173.916213  154.806477   \n",
       "4  173.758449  175.173183  3.802594  0.828725  162.272318  157.735769   \n",
       "\n",
       "           x7          x8  Label  \n",
       "0  176.730082  178.661229      1  \n",
       "1  173.217956  177.346512      1  \n",
       "2  170.023857  179.863322      1  \n",
       "3  176.045937  177.358669      1  \n",
       "4  174.503925  171.857373      1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"C:\\\\Users\\\\Crim\\\\Desktop\\\\RESEARCH_THESIS\\\\golfpose\\\\GolfMediaPipeData.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[173.38268005 162.90567338   1.68242825 ... 158.42686344 176.73008236\n",
      "  178.6612294 ]\n",
      " [165.25303778 156.93039561   7.23392467 ... 160.91415637 173.21795634\n",
      "  177.34651214]\n",
      " [161.5818915  162.96869754   3.5350505  ... 156.32963619 170.02385739\n",
      "  179.86332157]\n",
      " ...\n",
      " [170.30145786 137.80700653  24.55270026 ... 167.42825367 173.14388836\n",
      "  147.42581989]\n",
      " [166.25507142 148.85340556  28.3708355  ... 144.51118308 172.88904156\n",
      "  169.4377574 ]\n",
      " [177.88561146 150.09127057  18.96368122 ... 137.2537705  176.26022446\n",
      "  178.02589643]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('GolfMediaPipeData.csv' )\n",
    "X = df[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']]\n",
    "X = X.values\n",
    "print(X)\n",
    "y = df[['Label']]\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Crim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 5 5 5]\n",
      "Mediapipe Accuracy: 0.8905630452022204\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "clf = SVC(kernel='rbf', gamma=0.1, C=1, probability=True)\n",
    "\n",
    "clf.fit(X_scaled, y)\n",
    "\n",
    "y_pred = clf.predict(X_scaled)\n",
    "\n",
    "print(y_pred)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"Mediapipe Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = SVC(kernel='rbf', gamma=0.1, C=1, probability=True)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "print(y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the decision function values for the test data\n",
    "decision_values = clf.decision_function(X_test_scaled)\n",
    "\n",
    "max_indices = decision_values.argmax(axis=1)\n",
    "max_labels = clf.classes_[max_indices]\n",
    "\n",
    "# print the highest confidence level for each label\n",
    "for i in range(5):\n",
    "    max_confidence = decision_values[:,i][max_indices == i].max()\n",
    "    print(\"Highest confidence for label\", i, \":\", max_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.linspace(0.1, 1.0, 20)\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    clf, X, y, train_sizes=train_sizes, cv=5)\n",
    "\n",
    "# calculate the mean and standard deviation of the training and validation scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# plot the learning curve\n",
    "plt.plot(train_sizes, train_mean, label='Training score')\n",
    "plt.plot(train_sizes, test_mean, label='Cross-validation score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning curve for SVM with RBF kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_angles_test(results):\n",
    "  if results.pose_landmarks is None:\n",
    "      return None\n",
    "  \n",
    "  left_elbow_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST] , results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER])\n",
    "  right_elbow_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER])\n",
    "  left_shoulder_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP])\n",
    "  right_shoulder_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP])\n",
    "  left_hip_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE])\n",
    "  right_hip_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE])\n",
    "  left_knee_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE], results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HEEL])\n",
    "  right_knee_angles = calculate_angles(results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE], results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HEEL])\n",
    "\n",
    "  return [[left_elbow_angles, right_elbow_angles, left_shoulder_angles, right_shoulder_angles, left_hip_angles, right_hip_angles, left_knee_angles, right_knee_angles]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Set up Mediapipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "min_detection_confidence = 0.5\n",
    "min_tracking_confidence = 0.5\n",
    "\n",
    "video_file = './8.mp4'\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "highest_conf_frames = {}\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect the pose\n",
    "    with mp_pose.Pose(min_detection_confidence=min_detection_confidence,\n",
    "                      min_tracking_confidence=min_tracking_confidence) as pose:\n",
    "        results = pose.process(frame)\n",
    "        test_value = extract_angles_test(results)\n",
    "        print(test_value)\n",
    "        test_scaled_value = scaler.transform(test_value)\n",
    "        test_probabilities = clf.predict_proba(test_scaled_value)\n",
    "        test_prediction = np.argmax(test_probabilities)\n",
    "        test_confidence = test_probabilities[0][test_prediction] * 100\n",
    "        print(f\"Predicted label: {test_prediction}, confidence: {test_confidence:.2f}%\")\n",
    "\n",
    "        # Check if pose_landmarks attribute is not found or does not contain all expected landmarks\n",
    "        if not results.pose_landmarks or len(results.pose_landmarks.landmark) != 33:\n",
    "            continue\n",
    "\n",
    "        # Draw the pose landmarks on the image\n",
    "        annotated_image = frame.copy()\n",
    "\n",
    "        # Check if current frame has highest confidence level for predicted label\n",
    "        if test_prediction not in highest_conf_frames or test_confidence > highest_conf_frames[test_prediction][0]:\n",
    "            # Update dictionary with current frame as new highest confidence level frame\n",
    "            highest_conf_frames[test_prediction] = (test_confidence, annotated_image)\n",
    "\n",
    "    cv2.imshow('Pose Detection', annotated_image)\n",
    "\n",
    "    # Exit the loop when the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Display the highest confidence level frames for each predicted label\n",
    "for label, (confidence, frame) in highest_conf_frames.items():\n",
    "    print(f\"Label {label} has highest confidence level of {confidence:.2f}%\")\n",
    "    cv2.imshow(f\"Label {label}\", frame)\n",
    "    cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
